{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day7_hw.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfN22ljDQT1PhHBvjD+y0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdImran2021/DS_Days/blob/main/Day7_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgf-YlU8qj8o"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kq1Xm-cq5Mg"
      },
      "source": [
        "\n",
        "dataset = pd.read_csv(\"/content/loan_prediction.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiZ4d-BwDJCF",
        "outputId": "495aef14-57c7-4440-dee6-69b12c5852b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LP001002</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>5849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LP001003</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LP001005</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LP001006</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LP001008</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Loan_ID Gender Married  ... Credit_History Property_Area Loan_Status\n",
              "0  LP001002   Male      No  ...            1.0         Urban           Y\n",
              "1  LP001003   Male     Yes  ...            1.0         Rural           N\n",
              "2  LP001005   Male     Yes  ...            1.0         Urban           Y\n",
              "3  LP001006   Male     Yes  ...            1.0         Urban           Y\n",
              "4  LP001008   Male      No  ...            1.0         Urban           Y\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0yAdvtSETeu"
      },
      "source": [
        "dataset.dropna(axis = 0, inplace = True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFo2YAhjDM6U",
        "outputId": "12e1ec15-0fed-41bd-b2c7-3dd859942fb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "ohe.fit_transform(dataset[['Loan_ID','Gender','Married','Dependents','Education','Self_Employed','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','Property_Area']]).toarray()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vytqtmfgEsxk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la_znjIjq8et",
        "outputId": "623dc48b-3d51-4f77-a860-1f551ee0ce31"
      },
      "source": [
        "\n",
        "x = dataset.iloc[:,6].values\n",
        "y = dataset.iloc[:,7].values\n",
        "\n",
        "print(x)\n",
        "print(y)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4583  3000  2583  6000  5417  2333  3036  4006 12841  3200  3073  1853\n",
            "  1299  4950  3510  4887  7660  5955  2600  9560  2799  4226  1442  3167\n",
            "  4692  3500 12500  3667  4166  3748  3600  1800  3941  5649  5821  2645\n",
            "  4000  1928  3086  4230  4616 11500  2708  2132  3366  8080  3357  2500\n",
            "  3029  2609  4166  5726  3200 10750  7100  4300  3208  1875  3500  5266\n",
            "  3750  3750  1000  3167  3846  1378  3988  2366  2500  8566  5695  2958\n",
            "  6250  3273  4133  3620  2484  1977  4188  1759  4288  4843  3052 11417\n",
            "  3800  2071  5316 14583  3167  5568 10408  4166  2137  2957  4300 10513\n",
            "  2014  2718  3459  4895  4000  4583  3316 14999  4200  5042  5417  6950\n",
            "  2698 11757  2330 14866  1538 10000  4860  6277  2577  9166  2281  3254\n",
            " 39999  9538  4583  1863  7933  3089  4167  9323  4583  2439  2237  8000\n",
            "  3522  5708  4344  3497  2045  5516  3750  2333  6400  4600 33846  3625\n",
            " 39147  2178  9328  4885 12000  6033  3858  4191  3125  8333 11000  2600\n",
            "  4923  3500  3917  4408  3244  3975  2479  3418 10000  3430  7787  5703\n",
            "  3173  3850   150  3727  2221  4009  2971  6250  3250  6250  6400  2491\n",
            "  8333  3155  5500  3812  3315  5819  2510  2965  6250  3406  6050  9703\n",
            "  6608  2882  1809  1668  3427  2583  2661 16250  3083  6045  5250 14683\n",
            "  2060  3481  7200  5166  4095  4708  4333  2876  3237 11146  2833  2620\n",
            "  3900  2750  3993  3103 14583  4053  3927  2301  1811  3158  2600  3704\n",
            "  4124  9508  3075  4400  3153  2383  6875  4666  5000  2014  1800  5000\n",
            "  1625  4000  3762  2400 20233  2917  2927  2507  3399  3717 10000  2400\n",
            "  4342 15000  8666  4917  5818  4333  2500  4384  2935  2500  4160  2647\n",
            "  2378  4554  3173  2499  3083  2625  9083  8750  2666  5500  2423  8333\n",
            "  3875  3000  5167  4723  5000  4750  6822  6216  2500  6325 19730 15759\n",
            "  5185  9323  3062  4817  8750  3069  5391  5941  6000  7167  4566  2346\n",
            "  2333  5488  9167  9504  1993  3100  3180  3033  3902  1500  2889  2755\n",
            "  2500  1963  7441  4547  2167  2213  8300 81000  3867  6096  2253  2149\n",
            "  2995  2600  1600  1025  3246  5829  1820 14880  2666  4606  5935  2920\n",
            "  2717  8624  6500  2425  3750  1926 10416  7142  3660  7901  4707 37719\n",
            "  3466  4652  3340  2309  3948  2483  7085  3859  4301  3708  4354  8334\n",
            "  7740  3015  4166  6000  2947  4333  3450  2653  4691  5532 16525  6700\n",
            " 16667  4350  3095  2083 10833  8333  1958  3547 18333  4583  2435  3691\n",
            " 17263  3597  3326  2600  2895  6283   645  3159  4865  3814  3510  2479\n",
            " 13262  3598  6065  3283  2130  5815  3466  2031  4683  3400  2192  2500\n",
            "  5677  7948 17500  3775  5285  2679  6783  4281  3588 18165  6133  3617\n",
            "  2917  6417  4608  2138  2239  2768  3358  2526  5000  2785  3333  2454\n",
            "  3593  5468 10139  3887  4180  3675 19484  5923  5800  8799  3333  3400\n",
            "  2378  3166  3417 16666  6125  6406  3159  3229  1782  6540  1836  3166\n",
            "  2787  4283  2297  2165  2726  3000  6000  3859 16120  3833  6383  9963\n",
            "  5780  5703  3676 12000  3400  3987  3232  2900  4106  8072  7583  4583]\n",
            "[1.50800000e+03 0.00000000e+00 2.35800000e+03 0.00000000e+00\n",
            " 4.19600000e+03 1.51600000e+03 2.50400000e+03 1.52600000e+03\n",
            " 1.09680000e+04 7.00000000e+02 8.10600000e+03 2.84000000e+03\n",
            " 1.08600000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 5.62500000e+03 1.91100000e+03 0.00000000e+00\n",
            " 2.25300000e+03 1.04000000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 1.66700000e+03 3.00000000e+03 1.45900000e+03\n",
            " 7.21000000e+03 1.66800000e+03 0.00000000e+00 1.21300000e+03\n",
            " 2.33600000e+03 0.00000000e+00 0.00000000e+00 3.44000000e+03\n",
            " 2.27500000e+03 1.64400000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.16700000e+03 1.59100000e+03\n",
            " 2.20000000e+03 2.25000000e+03 2.85900000e+03 3.79600000e+03\n",
            " 0.00000000e+00 3.44900000e+03 0.00000000e+00 4.59500000e+03\n",
            " 2.25400000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 3.06600000e+03 1.87500000e+03 0.00000000e+00 1.77400000e+03\n",
            " 0.00000000e+00 4.75000000e+03 3.02200000e+03 4.00000000e+03\n",
            " 0.00000000e+00 1.88100000e+03 0.00000000e+00 2.53100000e+03\n",
            " 2.11800000e+03 0.00000000e+00 4.16700000e+03 2.90000000e+03\n",
            " 5.65400000e+03 1.82000000e+03 0.00000000e+00 0.00000000e+00\n",
            " 2.30200000e+03 9.97000000e+02 0.00000000e+00 3.54100000e+03\n",
            " 3.26300000e+03 3.80600000e+03 1.03000000e+03 1.12600000e+03\n",
            " 3.60000000e+03 7.54000000e+02 0.00000000e+00 0.00000000e+00\n",
            " 2.28300000e+03 2.14200000e+03 0.00000000e+00 0.00000000e+00\n",
            " 8.98000000e+03 0.00000000e+00 2.01400000e+03 3.85000000e+03\n",
            " 1.92900000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 7.75000000e+03 0.00000000e+00 3.50000000e+03 0.00000000e+00\n",
            " 1.43000000e+03 2.08300000e+03 0.00000000e+00 0.00000000e+00\n",
            " 2.03400000e+03 0.00000000e+00 4.48600000e+03 0.00000000e+00\n",
            " 1.42500000e+03 1.66600000e+03 8.30000000e+02 0.00000000e+00\n",
            " 3.75000000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 5.62500000e+03 1.04100000e+03\n",
            " 0.00000000e+00 1.28000000e+03 1.44700000e+03 0.00000000e+00\n",
            " 0.00000000e+00 3.33300000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 5.62500000e+03 7.36000000e+02 1.96400000e+03\n",
            " 1.61900000e+03 1.13000000e+04 0.00000000e+00 1.45100000e+03\n",
            " 7.25000000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 4.75000000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 2.58300000e+03 3.75000000e+03 0.00000000e+00 2.50000000e+03\n",
            " 0.00000000e+00 1.08300000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 2.53100000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 1.25000000e+03 0.00000000e+00 0.00000000e+00\n",
            " 3.02100000e+03 9.83000000e+02 1.80000000e+03 1.77500000e+03\n",
            " 0.00000000e+00 1.71700000e+03 2.79100000e+03 0.00000000e+00\n",
            " 0.00000000e+00 1.69500000e+03 0.00000000e+00 2.05400000e+03\n",
            " 0.00000000e+00 1.77900000e+03 1.26000000e+03 0.00000000e+00\n",
            " 0.00000000e+00 5.00000000e+03 1.98300000e+03 5.70100000e+03\n",
            " 1.30000000e+03 4.41700000e+03 4.33300000e+03 0.00000000e+00\n",
            " 0.00000000e+00 1.84300000e+03 1.86800000e+03 3.89000000e+03\n",
            " 0.00000000e+00 2.16700000e+03 7.10100000e+03 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.10000000e+03\n",
            " 2.20900000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 3.44700000e+03 1.38700000e+03 1.81100000e+03 1.56000000e+03\n",
            " 0.00000000e+00 0.00000000e+00 1.85700000e+03 2.22300000e+03\n",
            " 0.00000000e+00 1.84200000e+03 3.27400000e+03 1.30000000e+03\n",
            " 0.00000000e+00 2.42600000e+03 8.00000000e+02 9.85799988e+02\n",
            " 1.66600000e+03 3.05300000e+03 1.71700000e+03 2.00000000e+03\n",
            " 0.00000000e+00 0.00000000e+00 2.41600000e+03 0.00000000e+00\n",
            " 1.56000000e+03 3.33400000e+03 0.00000000e+00 0.00000000e+00\n",
            " 2.54100000e+03 2.92500000e+03 2.93400000e+03 0.00000000e+00\n",
            " 1.80300000e+03 2.50000000e+03 1.66600000e+03 1.86300000e+03\n",
            " 0.00000000e+00 0.00000000e+00 2.40500000e+03 0.00000000e+00\n",
            " 1.64000000e+03 0.00000000e+00 0.00000000e+00 2.16700000e+03\n",
            " 1.89000000e+02 0.00000000e+00 4.98300000e+03 0.00000000e+00\n",
            " 2.16000000e+03 2.45100000e+03 0.00000000e+00 1.79300000e+03\n",
            " 0.00000000e+00 4.60000000e+03 0.00000000e+00 1.58700000e+03\n",
            " 0.00000000e+00 1.22900000e+03 0.00000000e+00 2.45800000e+03\n",
            " 2.16800000e+03 6.25000000e+03 0.00000000e+00 4.16700000e+03\n",
            " 2.08300000e+03 0.00000000e+00 5.05000000e+02 3.16700000e+03\n",
            " 0.00000000e+00 1.66600000e+03 3.16700000e+03 0.00000000e+00\n",
            " 3.66700000e+03 2.33300000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 5.26600000e+03 0.00000000e+00\n",
            " 0.00000000e+00 7.87300000e+03 1.98700000e+03 9.23000000e+02\n",
            " 4.99600000e+03 0.00000000e+00 0.00000000e+00 4.23200000e+03\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.60000000e+03\n",
            " 2.41700000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 1.62500000e+03 1.40000000e+03 0.00000000e+00 1.45900000e+03\n",
            " 1.66600000e+03 1.80000000e+03 0.00000000e+00 0.00000000e+00\n",
            " 2.00000000e+04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 2.40000000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 2.03300000e+03 3.23700000e+03\n",
            " 0.00000000e+00 0.00000000e+00 2.00000000e+04 2.77300000e+03\n",
            " 1.41700000e+03 0.00000000e+00 1.71900000e+03 0.00000000e+00\n",
            " 4.30000000e+03 0.00000000e+00 0.00000000e+00 1.61200008e+01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.34000000e+03\n",
            " 0.00000000e+00 1.85100000e+03 0.00000000e+00 0.00000000e+00\n",
            " 5.06400000e+03 1.83300000e+03 1.99300000e+03 0.00000000e+00\n",
            " 1.21000000e+03 0.00000000e+00 1.71000000e+03 1.25500000e+03\n",
            " 1.73300000e+03 2.46600000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 2.56900000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 2.18800000e+03 0.00000000e+00 0.00000000e+00\n",
            " 1.66400000e+03 2.45100000e+03 2.07900000e+03 1.50000000e+03\n",
            " 0.00000000e+00 4.64800000e+03 1.01400000e+03 1.75000000e+03\n",
            " 2.25000000e+03 0.00000000e+00 0.00000000e+00 3.15000000e+03\n",
            " 0.00000000e+00 0.00000000e+00 2.43600000e+03 0.00000000e+00\n",
            " 0.00000000e+00 2.08300000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 2.15700000e+03 9.13000000e+02 1.70000000e+03\n",
            " 0.00000000e+00 4.41600000e+03 3.68300000e+03 0.00000000e+00\n",
            " 5.62400000e+03 1.48300000e+03 4.41600000e+03 3.01300000e+03\n",
            " 0.00000000e+00 1.28700000e+03 2.00400000e+03 2.03500000e+03\n",
            " 6.66600000e+03 3.66600000e+03 3.42800000e+03 1.63200000e+03\n",
            " 1.91500000e+03 0.00000000e+00 1.74200000e+03 0.00000000e+00\n",
            " 1.42400000e+03 7.16600000e+03 0.00000000e+00 0.00000000e+00\n",
            " 1.43000000e+03 1.30200000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 3.90600000e+03 0.00000000e+00\n",
            " 5.36000000e+02 0.00000000e+00 2.84500000e+03 0.00000000e+00\n",
            " 2.52400000e+03 1.95000000e+03 0.00000000e+00 1.78300000e+03\n",
            " 0.00000000e+00 2.01600000e+03 3.25000000e+03 2.33300000e+03\n",
            " 4.26600000e+03 1.03200000e+03 0.00000000e+00 2.66900000e+03\n",
            " 2.30600000e+03 2.42000000e+02 0.00000000e+00 2.05400000e+03\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.50000000e+03\n",
            " 0.00000000e+00 2.06400000e+03 1.75000000e+03 0.00000000e+00\n",
            " 1.62500000e+03 0.00000000e+00 4.61000000e+02 2.73900000e+03\n",
            " 2.23200000e+03 0.00000000e+00 3.38370000e+04 0.00000000e+00\n",
            " 1.91700000e+03 3.00000000e+03 1.52200000e+03 0.00000000e+00\n",
            " 0.00000000e+00 3.41600000e+03 0.00000000e+00 3.30000000e+03\n",
            " 0.00000000e+00 0.00000000e+00 1.00000000e+03 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 4.30100000e+03 0.00000000e+00\n",
            " 2.50000000e+03 1.41100000e+03 1.95000000e+03 0.00000000e+00\n",
            " 0.00000000e+00 2.40000000e+02 0.00000000e+00 0.00000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpS67fG_q_qd",
        "outputId": "c5ccceaf-a2bb-4953-d8e0-2ee11e5eca09"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.25)\n",
        "print(x_train)\n",
        "print(x_test)\n",
        "print(y_train)\n",
        "print(y_test)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3887  4180  2435  2483  7933  4606  6540 39999  5500  3917  2060  7085\n",
            "  4692  3155  2149  2014  3450  2785  3708  2500  4000  4750  3033  3717\n",
            " 15000  3800  2330  6608  8072  3875  2583  1025  2484  4124  5316  3727\n",
            "  4000  2192  3497 14683  4885  3326  2666  3400  8080  3859  2425  2666\n",
            "  7901  2479  2500  2333  3466  3357  4408 10750  2237  2221   150  6406\n",
            "  2661  3069  2900  6000  6277  3167 33846  4281  2014  3283  2500  6700\n",
            "  2045 14866  9538  2645  5488 14583  1299  2378  9323 11146  1378  3232\n",
            "  3902  5167  4333  1442  3459  3200  2718  3750  5468  1782  3237  3675\n",
            "  4166  5500  4006  3667  4723  3180  3975  3812  5923  2281  5703  3775\n",
            "  2301  3273  4708  4333 11417 16666  3704  4566  1600  3052  2947  3167\n",
            "  8624  2957  1853  2917  4283  3173  7200  5703  7142 39147  4923  1820\n",
            "  3166  4583  5285  3358  2165  6096  2895  5000  2499 14880  8334  2178\n",
            "  9504  2679  3466  2600  7787 17500  4350  5391  8566  8666  3250  1958\n",
            "  4333  3254  3900  2137  1800  2333  5935  3500  3691  4191 14583  5649\n",
            "  5185  3062  2708  6250  3208  9703  3000  5815  2130  2346  3748 10000\n",
            "  4053  2500  2454  8300  3481  3987  2213  3333  7948  2882  7583  3167\n",
            "  3333 12500  1977  3417  5818  4106  3597  9328  3750  3073  3075  2833\n",
            "  1928  4583  2423  3400  4230  4917 10408  4160  3620  6033  2510  4342\n",
            "  4583 10000  3427  3941  4707  4009  2787  5516  3000  3173  2500  2889\n",
            "  5532  3676  4652 16525 12000  1668  2600  3015  5677  9963  1926  5000\n",
            "  3762  5821  2526  4188  3153  6950  7660  4666  3547 10139  4860  3867\n",
            "  3598  3750  2600  2500  7100  2698  5042  3660  4547 13262  2755  4843\n",
            "  3593  9083  2309  2138  6400  1993  3625  6283  5780  1963  2400  4400\n",
            "  2253  2167  7441  3100   645  2600  4691  4167  6125  2995  4095  1800\n",
            "  3340  8799  2625  5955  3229  4616  3833  4166  2768 18333  5568  8333\n",
            "  4600  9167  5726  2971  5000  8750  3988  3406  3510  1500  1811  2132\n",
            "  3200  8333 10833 16120  1809  5250  3086  4887  3750  7167  3814  6000\n",
            "  6417  2071  5000  2239  4354  4301  3500  4133  4344  4288 18165 10513\n",
            "  2031  3083  8333  3246 15759  3617  2479  3159  6783  6216  3859  2507\n",
            "  7740  1625  2653  2600  4000  3846 12000  3089  5166  3083  6250  4865]\n",
            "[10000  5417 11757  2620  3400  3095  2799  6383  4384  3510  6822  3244\n",
            "  4895  2439  5417  4166 10416  1836  3125 12841  3036  4950  6045  2965\n",
            "  4554  1000  4166  3366  2876  3159  6875  9560  3418  2726  2491 16667\n",
            "  5800  8333  1759  4300  2920  2400  3166  6250  4200  3522 19484  2609\n",
            "  6000 11500  6065  2717 11000  3430  2500 81000  4583 20233  2917 16250\n",
            "  5695  2383  6050  6133  2750  2366  8750  2935  6400 14999  3600  1863\n",
            "  3000  9166  3029  2958  3103  6250  9508 17263  4583  4817  2927  6500\n",
            "  3993  5941  6000  2333  1875  3588 19730  4608  2083  2577  5829  3158\n",
            "  5266  3948  4583  2583  3316  6325  5819  2647  1538 37719  3927  4683\n",
            "  3858  3500  2378  2297  8000  5708  3315  9323  3850  3399  4300  4226]\n",
            "[ 2669.         2306.            0.         2466.            0.\n",
            "     0.            0.            0.            0.            0.\n",
            "  2209.            0.            0.         1779.         3237.\n",
            "  1929.         2079.         2016.         2569.            0.\n",
            "  2500.         2333.         1459.            0.            0.\n",
            "  3600.         4486.            0.          240.            0.\n",
            "  2167.         2773.         2302.            0.            0.\n",
            "  1775.         7750.         1742.         1964.         2100.\n",
            "     0.          913.         2083.         2500.         2250.\n",
            "     0.         2340.         4300.         1833.            0.\n",
            "     0.         2417.         1210.         2859.            0.\n",
            "     0.            0.            0.         1800.            0.\n",
            "  7101.            0.            0.            0.            0.\n",
            "  2283.            0.            0.         2925.         2035.\n",
            "  3796.         1750.         1619.            0.            0.\n",
            "  3440.            0.            0.         1086.            0.\n",
            "     0.            0.         1881.         1950.         1666.\n",
            "  3167.         2451.            0.            0.          700.\n",
            "     0.         4750.         1032.         2232.            0.\n",
            "   242.            0.         1260.         1526.         1459.\n",
            "     0.            0.         2531.            0.         2054.\n",
            "     0.            0.            0.          985.7999878  1820.\n",
            "  1387.         1811.         1126.            0.         2000.\n",
            "     0.        20000.         1030.         1664.            0.\n",
            "     0.            0.         2840.          536.         3000.\n",
            "     0.            0.            0.            0.         4750.\n",
            "     0.         1719.            0.         2083.         1430.\n",
            "     0.            0.            0.            0.            0.\n",
            "  2458.            0.            0.            0.            0.\n",
            "  1302.         3428.         1911.            0.            0.\n",
            "     0.            0.            0.         4983.            0.\n",
            "  2436.         2451.            0.            0.         8980.\n",
            "  2934.         1516.            0.         1083.            0.\n",
            "     0.            0.            0.            0.         1987.\n",
            "  1167.         1695.         3066.            0.            0.\n",
            "  3666.         6666.         1600.         1668.            0.\n",
            "  2426.        20000.         2333.            0.            0.\n",
            "  1411.            0.            0.         7166.         1843.\n",
            "     0.         4000.         3250.         3000.          997.\n",
            "  1750.         2160.            0.         2157.            0.\n",
            "     0.         8106.         2416.         1857.         1644.\n",
            "     0.          505.            0.            0.            0.\n",
            "     0.            0.            0.            0.         1983.\n",
            "   189.            0.         1666.            0.         2336.\n",
            "  1993.         1717.         1917.        11300.         3416.\n",
            "  3021.         4600.            0.         4648.         4301.\n",
            "     0.         1014.            0.         3890.         1717.\n",
            "  2188.         1424.            0.         1851.            0.\n",
            "  1666.            0.         1783.            0.         1560.\n",
            "     0.            0.            0.            0.            0.\n",
            "   830.            0.         1287.            0.         1700.\n",
            "     0.            0.         2034.         2083.         5064.\n",
            "     0.            0.            0.         3806.         4266.\n",
            "     0.         1255.            0.            0.         1625.\n",
            "     0.         4416.            0.            0.         1863.\n",
            "     0.         2033.         2400.            0.         1400.\n",
            "  3683.            0.            0.         1447.         1625.\n",
            "     0.         3447.         1213.         1710.            0.\n",
            "  6250.         5625.         2739.            0.            0.\n",
            "     0.         1950.            0.         2142.         3167.\n",
            "     0.            0.         4595.         2791.         3667.\n",
            "  4996.            0.         4417.            0.         1800.\n",
            "  1666.         1591.         2254.            0.            0.\n",
            "     0.         1868.            0.            0.            0.\n",
            "     0.            0.         1483.            0.            0.\n",
            "   754.         2541.         2524.            0.            0.\n",
            "     0.            0.          736.         3263.            0.\n",
            "  3850.         1632.         2168.            0.         1417.\n",
            "     0.            0.         3013.            0.            0.\n",
            "     0.         3300.            0.            0.         1803.\n",
            "  1500.         2500.         2275.            0.            0.\n",
            "  1280.            0.            0.         1300.         5624.       ]\n",
            "[0.00000000e+00 0.00000000e+00 0.00000000e+00 2.22300000e+03\n",
            " 2.50000000e+03 0.00000000e+00 2.25300000e+03 1.00000000e+03\n",
            " 1.79300000e+03 4.41600000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 3.33300000e+03 4.19600000e+03 0.00000000e+00\n",
            " 0.00000000e+00 3.38370000e+04 2.58300000e+03 1.09680000e+04\n",
            " 2.50400000e+03 0.00000000e+00 0.00000000e+00 5.70100000e+03\n",
            " 1.22900000e+03 3.02200000e+03 7.21000000e+03 2.20000000e+03\n",
            " 1.56000000e+03 4.61000000e+02 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 2.05400000e+03 2.25000000e+03\n",
            " 0.00000000e+00 3.75000000e+03 3.54100000e+03 0.00000000e+00\n",
            " 1.61200008e+01 2.16700000e+03 2.06400000e+03 0.00000000e+00\n",
            " 1.43000000e+03 0.00000000e+00 0.00000000e+00 3.44900000e+03\n",
            " 0.00000000e+00 0.00000000e+00 2.00400000e+03 0.00000000e+00\n",
            " 0.00000000e+00 1.25000000e+03 2.11800000e+03 0.00000000e+00\n",
            " 5.62500000e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 4.16700000e+03 3.33400000e+03 4.33300000e+03 3.90600000e+03\n",
            " 1.84200000e+03 2.53100000e+03 4.16700000e+03 0.00000000e+00\n",
            " 7.25000000e+03 0.00000000e+00 0.00000000e+00 1.04100000e+03\n",
            " 1.66600000e+03 0.00000000e+00 0.00000000e+00 2.90000000e+03\n",
            " 1.30000000e+03 5.65400000e+03 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 9.23000000e+02 2.40500000e+03 0.00000000e+00\n",
            " 3.27400000e+03 4.23200000e+03 0.00000000e+00 1.45100000e+03\n",
            " 1.87500000e+03 0.00000000e+00 5.26600000e+03 2.84500000e+03\n",
            " 3.15000000e+03 3.75000000e+03 0.00000000e+00 3.05300000e+03\n",
            " 1.77400000e+03 1.73300000e+03 1.50800000e+03 2.35800000e+03\n",
            " 3.50000000e+03 0.00000000e+00 5.00000000e+03 1.58700000e+03\n",
            " 1.42500000e+03 0.00000000e+00 8.00000000e+02 1.91500000e+03\n",
            " 0.00000000e+00 1.66700000e+03 0.00000000e+00 1.52200000e+03\n",
            " 0.00000000e+00 5.62500000e+03 0.00000000e+00 7.87300000e+03\n",
            " 9.83000000e+02 1.64000000e+03 2.01400000e+03 1.04000000e+03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ppBKpRyfrJsl",
        "outputId": "c868fdaa-05ae-48ac-af79-89200b7c4042"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "print(x_train)\n",
        "print(x_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-5b945226462e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 3887.  4180.  2435.  2483.  7933.  4606.  6540. 39999.  5500.  3917.\n  2060.  7085.  4692.  3155.  2149.  2014.  3450.  2785.  3708.  2500.\n  4000.  4750.  3033.  3717. 15000.  3800.  2330.  6608.  8072.  3875.\n  2583.  1025.  2484.  4124.  5316.  3727.  4000.  2192.  3497. 14683.\n  4885.  3326.  2666.  3400.  8080.  3859.  2425.  2666.  7901.  2479.\n  2500.  2333.  3466.  3357.  4408. 10750.  2237.  2221.   150.  6406.\n  2661.  3069.  2900.  6000.  6277.  3167. 33846.  4281.  2014.  3283.\n  2500.  6700.  2045. 14866.  9538.  2645.  5488. 14583.  1299.  2378.\n  9323. 11146.  1378.  3232.  3902.  5167.  4333.  1442.  3459.  3200.\n  2718.  3750.  5468.  1782.  3237.  3675.  4166.  5500.  4006.  3667.\n  4723.  3180.  3975.  3812.  5923.  2281.  5703.  3775.  2301.  3273.\n  4708.  4333. 11417. 16666.  3704.  4566.  1600.  3052.  2947.  3167.\n  8624.  2957.  1853.  2917.  4283.  3173.  7200.  5703.  7142. 39147.\n  4923.  1820.  3166.  4583.  5285.  3358.  2165.  6096.  2895.  5000.\n  2499. 14880.  8334.  2178.  9504.  2679.  3466.  2600.  7787. 17500.\n  4350.  5391.  8566.  8666.  3250.  1958.  4333.  3254.  3900.  2137.\n  1800.  2333.  5935.  3500.  3691.  4191. 14583.  5649.  5185.  3062.\n  2708.  6250.  3208.  9703.  3000.  5815.  2130.  2346.  3748. 10000.\n  4053.  2500.  2454.  8300.  3481.  3987.  2213.  3333.  7948.  2882.\n  7583.  3167.  3333. 12500.  1977.  3417.  5818.  4106.  3597.  9328.\n  3750.  3073.  3075.  2833.  1928.  4583.  2423.  3400.  4230.  4917.\n 10408.  4160.  3620.  6033.  2510.  4342.  4583. 10000.  3427.  3941.\n  4707.  4009.  2787.  5516.  3000.  3173.  2500.  2889.  5532.  3676.\n  4652. 16525. 12000.  1668.  2600.  3015.  5677.  9963.  1926.  5000.\n  3762.  5821.  2526.  4188.  3153.  6950.  7660.  4666.  3547. 10139.\n  4860.  3867.  3598.  3750.  2600.  2500.  7100.  2698.  5042.  3660.\n  4547. 13262.  2755.  4843.  3593.  9083.  2309.  2138.  6400.  1993.\n  3625.  6283.  5780.  1963.  2400.  4400.  2253.  2167.  7441.  3100.\n   645.  2600.  4691.  4167.  6125.  2995.  4095.  1800.  3340.  8799.\n  2625.  5955.  3229.  4616.  3833.  4166.  2768. 18333.  5568.  8333.\n  4600.  9167.  5726.  2971.  5000.  8750.  3988.  3406.  3510.  1500.\n  1811.  2132.  3200.  8333. 10833. 16120.  1809.  5250.  3086.  4887.\n  3750.  7167.  3814.  6000.  6417.  2071.  5000.  2239.  4354.  4301.\n  3500.  4133.  4344.  4288. 18165. 10513.  2031.  3083.  8333.  3246.\n 15759.  3617.  2479.  3159.  6783.  6216.  3859.  2507.  7740.  1625.\n  2653.  2600.  4000.  3846. 12000.  3089.  5166.  3083.  6250.  4865.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FKRKx79CPiN",
        "outputId": "1513af62-a3d6-480b-a5f2-4397ac3a732a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c5af54794819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 3887.  4180.  2435.  2483.  7933.  4606.  6540. 39999.  5500.  3917.\n  2060.  7085.  4692.  3155.  2149.  2014.  3450.  2785.  3708.  2500.\n  4000.  4750.  3033.  3717. 15000.  3800.  2330.  6608.  8072.  3875.\n  2583.  1025.  2484.  4124.  5316.  3727.  4000.  2192.  3497. 14683.\n  4885.  3326.  2666.  3400.  8080.  3859.  2425.  2666.  7901.  2479.\n  2500.  2333.  3466.  3357.  4408. 10750.  2237.  2221.   150.  6406.\n  2661.  3069.  2900.  6000.  6277.  3167. 33846.  4281.  2014.  3283.\n  2500.  6700.  2045. 14866.  9538.  2645.  5488. 14583.  1299.  2378.\n  9323. 11146.  1378.  3232.  3902.  5167.  4333.  1442.  3459.  3200.\n  2718.  3750.  5468.  1782.  3237.  3675.  4166.  5500.  4006.  3667.\n  4723.  3180.  3975.  3812.  5923.  2281.  5703.  3775.  2301.  3273.\n  4708.  4333. 11417. 16666.  3704.  4566.  1600.  3052.  2947.  3167.\n  8624.  2957.  1853.  2917.  4283.  3173.  7200.  5703.  7142. 39147.\n  4923.  1820.  3166.  4583.  5285.  3358.  2165.  6096.  2895.  5000.\n  2499. 14880.  8334.  2178.  9504.  2679.  3466.  2600.  7787. 17500.\n  4350.  5391.  8566.  8666.  3250.  1958.  4333.  3254.  3900.  2137.\n  1800.  2333.  5935.  3500.  3691.  4191. 14583.  5649.  5185.  3062.\n  2708.  6250.  3208.  9703.  3000.  5815.  2130.  2346.  3748. 10000.\n  4053.  2500.  2454.  8300.  3481.  3987.  2213.  3333.  7948.  2882.\n  7583.  3167.  3333. 12500.  1977.  3417.  5818.  4106.  3597.  9328.\n  3750.  3073.  3075.  2833.  1928.  4583.  2423.  3400.  4230.  4917.\n 10408.  4160.  3620.  6033.  2510.  4342.  4583. 10000.  3427.  3941.\n  4707.  4009.  2787.  5516.  3000.  3173.  2500.  2889.  5532.  3676.\n  4652. 16525. 12000.  1668.  2600.  3015.  5677.  9963.  1926.  5000.\n  3762.  5821.  2526.  4188.  3153.  6950.  7660.  4666.  3547. 10139.\n  4860.  3867.  3598.  3750.  2600.  2500.  7100.  2698.  5042.  3660.\n  4547. 13262.  2755.  4843.  3593.  9083.  2309.  2138.  6400.  1993.\n  3625.  6283.  5780.  1963.  2400.  4400.  2253.  2167.  7441.  3100.\n   645.  2600.  4691.  4167.  6125.  2995.  4095.  1800.  3340.  8799.\n  2625.  5955.  3229.  4616.  3833.  4166.  2768. 18333.  5568.  8333.\n  4600.  9167.  5726.  2971.  5000.  8750.  3988.  3406.  3510.  1500.\n  1811.  2132.  3200.  8333. 10833. 16120.  1809.  5250.  3086.  4887.\n  3750.  7167.  3814.  6000.  6417.  2071.  5000.  2239.  4354.  4301.\n  3500.  4133.  4344.  4288. 18165. 10513.  2031.  3083.  8333.  3246.\n 15759.  3617.  2479.  3159.  6783.  6216.  3859.  2507.  7740.  1625.\n  2653.  2600.  4000.  3846. 12000.  3089.  5166.  3083.  6250.  4865.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOckDslAF1SD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}